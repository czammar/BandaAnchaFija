# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T0] = mu.f[, T0]
Sigma.s[, , T0] = Sigma.f[, , T0]
for (t in (T0 - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
T0 = 50
x = matrix(cos(c(1:T)/10), 1, T0)
R = 0.2
mu0 = 0
Sigma0 = 1
G = 1
Q = 0.02
H = 1
F0 = 1
y = matrix(x + rnorm(T0, sd = sqrt(R)), nrow = 1, ncol = T0)
results.KF = kalman(y, F0, G, Q, H, R, mu0, Sigma0)
mu.f = results.KF$mu.f
Sigma.f = results.KF$Sigma.f
function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T0 = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T0)
Sigma.p = array(0, c(dx, dx, T0))
mu.f = matrix(0, nrow = dx, ncol = T0)
Sigma.f = array(0, c(dx, dx, T0))
mu.s = matrix(0, nrow = dx, ncol = T0)
Sigma.s = array(0, c(dx, dx, T0))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T0)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T0] = mu.f[, T0]
Sigma.s[, , T0] = Sigma.f[, , T0]
for (t in (T0 - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
T0 = 50
x = matrix(cos(c(1:T0)/10), 1, T0)
R = 0.2
mu0 = 0
Sigma0 = 1
G = 1
Q = 0.02
H = 1
F0 = 1
y = matrix(x + rnorm(T0, sd = sqrt(R)), nrow = 1, ncol = T0)
results.KF = kalman(y, F0, G, Q, H, R, mu0, Sigma0)
mu.f = results.KF$mu.f
Sigma.f = results.KF$Sigma.f
ggplot2()+ geom_point(aes(1:50,mu.f))
library(tidyverse)
ggplot2()+ geom_point(aes(1:50,mu.f))
ggplot()+ geom_point(aes(1:50,mu.f))
ggplot()+ geom_point(aes(1:50,mu.f[2,]))
mu.f
dim(mu.f)
ggplot()+ geom_point(aes(1:50,mu.f[1,]))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))+geom_point(aes(1:50,x, color = 'red'))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'red'))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'blue'))
mu.p = results.KF$mu.p
mu.s = results.KF$mu.s
ggplot()+ geom_point(aes(1:50,mu.s[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'blue'))
library(tidyverse)
function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T0 = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T0)
Sigma.p = array(0, c(dx, dx, T0))
mu.f = matrix(0, nrow = dx, ncol = T0)
Sigma.f = array(0, c(dx, dx, T0))
mu.s = matrix(0, nrow = dx, ncol = T0)
Sigma.s = array(0, c(dx, dx, T0))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T0)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T0] = mu.f[, T0]
Sigma.s[, , T0] = Sigma.f[, , T0]
for (t in (T0 - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
T0 = 50
x = matrix(cos(c(1:T0)/10), 1, T0)
R = 0.2
mu0 = 0
Sigma0 = 1
G = 1
Q = 0.02
H = 1
F0 = 1
y = matrix(x + rnorm(T0, sd = sqrt(R)), nrow = 1, ncol = T0)
results.KF = kalman(y, F0, G, Q, H, R, mu0, Sigma0)
mu.f = results.KF$mu.f
Sigma.f = results.KF$Sigma.f
mu.p = results.KF$mu.p
mu.s = results.KF$mu.s
ggplot()+ geom_point(aes(1:50,mu.p[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'blue'))
?gamma
?dgamma
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
qgamma(0.1, alpha1, s1)
pgamma(0.01, alpha1, s1)
?pnorm
pnorm(0.01, mu1, sigma1)
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- alpha1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.01, mu1, sigma1)
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- alpha1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.01, mu1, sigma1)
sigma1 <- alpha1/136.5
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- mu1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.01, mu1, sigma1)
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- mu1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.1, mu1, sigma1)
mu2 <- 9/92.5
sigma2 <- mu2/92.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.1, mu2, sigma2)
# probabilidad de que theta sea menor a 0.1
print("Caso 1")
pnorm(0.1, mu1, sigma1)
###### ----- Simulacion para caso 2 ----- ######
mu2 <- 9/92.5
sigma2 <- mu2/92.5
# probabilidad de que theta sea menor a 0.1
print("Caso 2")
pnorm(0.1, mu2, sigma2)
print("Caso 1")
pnorm(0.1, mu1, sigma1)
mu1 <- 16/136.5
sigma1 <- mu1/136.5
# probabilidad de que theta sea menor a 0.1
print("Caso 1")
pnorm(0.1, mu1, sigma1)
mu2 <- 9/92.5
sigma2 <- mu2/92.5
# probabilidad de que theta sea menor a 0.1
print("Caso 2")
pnorm(0.1, mu2, sigma2)
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library("tidyverse")
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library(gridExtra)
library(grid)
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library(gridExtra)
library(grid)
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
View(p1)
p1
p2
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library(shiny); runApp('/media/Box/Aprendizaje_Maquina/Projecto/BAF_shiny.R')
beta(1,1)
beta(0.4,0.9)
choose(66,64)
devtools::install_github('diegovalle/mxmaps')
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
devtools::install_github('diegovalle/mxmaps')
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
devtools::install_github('diegovalle/mxmaps')
install.packages("tidyverse")
devtools::install_github('diegovalle/mxmaps')
install.packages("devtools")
devtools::install_github('diegovalle/mxmaps')
library(mxmaps)
install.packages(c("R2OpenBUGS", "R2jags"))
install.packages("corrplot")
library(readr)
library(tidyverse)
library(readxl)
# Establece directorio de trabajo
setwd("/media/Box/Aprendizaje_Maquina/Projecto")
# Crear las bases de datos para trabajar
source("creating_baf.R") # Accesos de banda ancha fija a junio/2019 BIT del IFT
source("creating_conapo.R") # Indice marginacion y porcentaje pob con menos de 2 salarios min, 2015 CONAPO
source("creating_inafed.R") # Superficie de municipios, INAFED
#source("creating_indiceinfraestructura.R")  # Indice infraestructura TII - centro de estudios IFT
source("creating_indicadores_serviciostelecom_viviendas_.R")  # Indicadores de disponiblidad de servicios de telecomunicaciones Encuesta intercensal 2015, INEGI
source("creating_hogares.R") # Hogares por municipios Encuesta intercensal 2015, INEGI
source("creating_poblacion.R") # Poblacion por municipios Encuesta intercensal 2015, INEGI
source("creating_humandevelop_index.R") # Programa de las Naciones Unidas para el Desarrollo (PNUD), datos del Indice de desarollo humano 2015
# Elimina variables auxiliares
rm(index, left_path,name_state,right_path,states_list,cleaning_hog_state,cleaning_pop_state)
# Consolidamos las bases
df <- left_join(hogares2015,poblacion2015, by = "K_ENTIDAD_MUNICIPIO")
df <- left_join(df,conapo, by = "K_ENTIDAD_MUNICIPIO")
df <- left_join(df,INAFED, by = "K_ENTIDAD_MUNICIPIO")
df <- left_join(df,indicadores_servicios2015, by = "K_ENTIDAD_MUNICIPIO")
df <- left_join(df,BAF_062019, by = "K_ENTIDAD_MUNICIPIO")
## El detalle de accesos a nivel municipal con NA se imputa con cero
df <- df %>% mutate_all(~replace(., is.na(.), 0))
df$SUPERFICIE<- as.numeric(df$SUPERFICIE)
df$PO2SM<- as.numeric(df$PO2SM)
# Se eliminan columas sin interes para el analisis
df$K_ENTIDAD<-NULL
df$K_MUNICIPIO<-NULL
df$ANIO<-NULL
df$MES<-NULL
# df1 <- df
# Se cambian algunas variables de caracteres a numericas
# df1 <- df1 %>% select(-K_ENTIDAD_MUNICIPIO,-GM)
df$SPRIM <- as.numeric(df$SPRIM)
df$OVSDE <- as.numeric(df$OVSDE)
df$VHAC <- as.numeric(df$VHAC)
df$OVPT <- as.numeric(df$OVPT)
df$`PL<5000` <- as.numeric(df$`PL<5000`)
# Crea variable de densidad de hogares por kilometros cuadrados
df$DENS_HOGS <- 0
for (i in 1:nrow(df)){
df$DENS_HOGS[i]<- df$HOGARES[i]/df$SUPERFICIE[i]*100
}
# Crea variable de densidad de personas por kilometros cuadrados
#df <- df %>% mutate(DENS_HOGS = df$HOGARES/df$SUPERFICIE)
df$DENS_HABS <- 0
for (i in 1:nrow(df)){
df$DENS_HABS[i]<- df$HOGARES[i]/df$SUPERFICIE[i]*100
}
# Crea variable de penetracion de BAF por cada 100 hogares y la penetracion de cable coaxial + fibra optica
#df <- df %>% mutate(PEN_BAF_HOGS = df$ALL_ACCESS/df$HOGARES*100)
df$PEN_BAF_HOGS_COAXFO <- 0
for (i in 1:nrow(df)){
df$PEN_BAF_HOGS_COAXFO[i]<- df$COAX_FO[i]/df$HOGARES[i]*100
}
# Crea variable de penetracion de BAF por cada 100 habitantes y la penetracion de cable coaxial + fibra optica
#df <- df %>% mutate(PEN_BAF_HABS = df$ALL_ACCESS/df$HOGARES*100)
df$PEN_BAF_HABS_COAXFO <- 0
for (i in 1:nrow(df)){
df$PEN_BAF_HABS_COAXFO[i]<- df$COAX_FO[i]/df$POBLACION[i]*100
}
# Creamos una columna para clasificar los municipios segun su grado de penetracion.
#La clasificación de Penetracion de Fibra Óptica y Cable Coaxial:
# Sin cobertura=0
# Muy baja 0>25%
# Baja 25%>50%
# Media 50%>75%
# Alta 75%>100%
# Muy Alta 100%
df$CLASS_PEN_BAF_HOGS_COAXFO <- 0
for (index in 1:nrow(df)){
df$CLASS_PEN_BAF_HOGS_COAXFO[index] <- if_else(df$PEN_BAF_HOGS_COAXFO[index]==0,0,
if_else(df$PEN_BAF_HOGS_COAXFO[index]<=25,1,
if_else(df$PEN_BAF_HOGS_COAXFO[index]<=50,2,
if_else(df$PEN_BAF_HOGS_COAXFO[index]<=75,3,
if_else(df$PEN_BAF_HOGS_COAXFO[index]<=100,4,5)))))
}
# Creamos una columna para clasificar los municipios segun su grado de penetracion.
#La clasificación de Penetracion de Fibra Óptica y Cable Coaxial:
# Sin cobertura=0
# Muy baja 0>25%
# Baja 25%>50%
# Media 50%>75%
# Alta 75%>100%
# Muy Alta 100%
df$CLASS_PEN_BAF_HABS_COAXFO <- 0
for (index in 1:nrow(df)){
df$CLASS_PEN_BAF_HABS_COAXFO[index] <- if_else(df$PEN_BAF_HABS_COAXFO[index]==0,0,
if_else(df$PEN_BAF_HABS_COAXFO[index]<=10,1,
if_else(df$PEN_BAF_HABS_COAXFO[index]<=20,2,
if_else(df$PEN_BAF_HABS_COAXFO[index]<=30.92,3,4))))
}
#----- Agregamos una columna que nos diga la region socioecnomica a la que pertenece el municipio
RegionesSocioEcono <- read_csv("RegionesSocioEcono.csv",
col_types = cols(NOM_ABRE_ENTIDAD = col_skip(),
NOM_ENTIDAD = col_skip(), NUM = col_skip()))
df <- df %>% mutate(K_ENTIDAD = substr(K_ENTIDAD_MUNICIPIO,1,2))
df <- left_join(df,RegionesSocioEcono, by = "K_ENTIDAD")
df$K_ENTIDAD<-NULL
for (index in 1:nrow(df)){
df$REG_SOCIOECONOM[index] <- if_else(df$REG_SOCIOECONOM[index]=="Centronorte",1,
if_else(df$REG_SOCIOECONOM[index]=="Centrosur",2,
if_else(df$REG_SOCIOECONOM[index]=="Noreste",3,
if_else(df$REG_SOCIOECONOM[index]=="Noroeste",4,
if_else(df$REG_SOCIOECONOM[index]=="Occidente",5,
if_else(df$REG_SOCIOECONOM[index]=="Oriente",6,
if_else(df$REG_SOCIOECONOM[index]=="Sureste",7,8)))))))
}
# Adjuntamos los datos de indices de derechos humanos
df <- left_join(df, hd_index2015, by = "K_ENTIDAD_MUNICIPIO")
# ---- Seleccionamos columnas para el analisis
#df1<- df %>% select(HOGARES, POBLACION, PO2SM, IM, SUPERFICIE, INFRA_INDEX, ALL_ACCESS, NUM_OPS, DENS_HOGS, PEN_CLASS)
#### ---- Intentemos Lasso
df1 <-df %>% select(-c(NUM_OPS,K_ENTIDAD_MUNICIPIO, IM, GM, CABLE_COAXIAL, FIBRA_OPTICA, SATELITAL, TERRESTRE_FIJO_INALAMBRICO, OTRAS_TECNOLOGIAS, SIN_TECNOLOGIA_ESPECIFICADA, ALL_ACCESS, DSL, COAX_FO, PEN_BAF_HOGS_COAXFO, PEN_BAF_HABS_COAXFO, CLASS_PEN_BAF_HOGS_COAXFO, CLASS_PEN_BAF_HABS_COAXFO, ANOS_ESPERADOS_DE_ESCOLARIZACIÓN, TASA_DE_MORTALIDAD_INFANTIL, INDICE_DE_EDUCACION,INDICE_DE_SALUD, INDICE_DE_INGRESO,IDH))
df2 <- df %>% select(PEN_BAF_HABS_COAXFO)
library(glmnet)
fit = glmnet(as.matrix(df1[!is.na(df1$INGRESOPC_ANUAL),]), as.matrix(df2[!is.na(df1$INGRESOPC_ANUAL),]))
plot(fit, label=TRUE)
# df1 <- df1 %>% select(ALL_ACCESS,COAX_FO,HOGARES,POBLACION, ANALF, SPRIM, OVSDE,OVSEE, OVSAE, VHAC, OVPT,`PL<5000`,PO2SM,IM)
df1 <- df1 %>%select(-PEN_CLASS,PEN_CLASS)
write_csv(df1, "BAF_06209_selected.csv")
#library(corrplot)
#M<-cor(df1)
#corrplot(M, method="circle")#
#corrplot(M, method="number")
library(readr)
Ecobicis_Final <- read_csv("/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/Ecobicis_Final.csv",
col_types = cols(bici = col_character(),
ciclo_estacion_arribo = col_character(),
ciclo_estacion_retiro = col_character(),
fecha_arribo = col_character(), fecha_retiro = col_character(),
genero_usuario = col_character(),
hora_arribo = col_character(), hora_retiro = col_character(),
hora_retiro_int = col_character(),
nearbystation0 = col_character()))
View(Ecobicis_Final)
library(shiny)
library(plotly)
library(ggplot2)
library(dplyr)
library(tidyverse)
View(Ecobicis_Final)
glimpse(Ecobicis_Final)
Ecobicis_Final %>% select_if(is.character) %>% names()
Ecobicis_Final <- read_csv("/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/Ecobicis_Final.csv",
+     col_types = cols(bici = col_character(),
ciclo_estacion_arribo = col_character(),
ciclo_estacion_retiro = col_character(),
fecha_arribo = col_character(), fecha_retiro = col_character(),
genero_usuario = col_character(),
hora_arribo = col_character(), hora_retiro = col_character(),
hora_retiro_int = col_character(),
nearbystation0 = col_character()))
Ecobicis_Final <- read_csv("/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/Ecobicis_Final.csv",
col_types = cols(bici = col_character(),
ciclo_estacion_arribo = col_character(),
ciclo_estacion_retiro = col_character(),
genero_usuario = col_character(),
hora_arribo = col_character(), hora_retiro = col_character(),
hora_retiro_int = col_character(),
nearbystation0 = col_character(),
nearbystation1 = col_character()))
Ecobicis_Final %>% select_if(is.character) %>% names()
runApp('/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/shiny_dashboard.R')
runApp('/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/shiny_dashboard.R')
runApp('/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/shiny_dashboard.R')
